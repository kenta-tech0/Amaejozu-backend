"""
ãƒãƒƒãƒã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ãƒ¼ã‚µãƒ¼ãƒ“ã‚¹

APSchedulerã‚’ä½¿ç”¨ã—ã¦å®šæœŸãƒãƒƒãƒå‡¦ç†ã‚’å®Ÿè¡Œã™ã‚‹
- ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚¦ã‚©ãƒ¼ãƒ ã‚¢ãƒƒãƒ—: 6æ™‚é–“ã”ã¨
- ä¾¡æ ¼æ›´æ–°: 6æ™‚é–“ã”ã¨

æ¥½å¤©APIãƒ¬ãƒ¼ãƒˆåˆ¶é™: 1ãƒªã‚¯ã‚¨ã‚¹ãƒˆ/ç§’
- ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚¦ã‚©ãƒ¼ãƒ ã‚¢ãƒƒãƒ—: ç´„18ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ Ã— 1ç§’ = ç´„18ç§’
- ä¾¡æ ¼æ›´æ–°: å•†å“æ•° Ã— 1ç§’ï¼ˆãƒªãƒˆãƒ©ã‚¤å«ã‚€ï¼‰

åŒæ™‚å®Ÿè¡Œé˜²æ­¢ã®ãŸã‚ã€ã‚¸ãƒ§ãƒ–ã¯ãƒ­ãƒƒã‚¯ã§æ’ä»–åˆ¶å¾¡ã™ã‚‹
"""

import logging
import threading
from apscheduler.schedulers.background import BackgroundScheduler
from apscheduler.triggers.interval import IntervalTrigger
from apscheduler.triggers.cron import CronTrigger
from datetime import datetime

logger = logging.getLogger(__name__)

# ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ãƒ¼ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ï¼ˆã‚°ãƒ­ãƒ¼ãƒãƒ«ï¼‰
scheduler = BackgroundScheduler()

# æ¥½å¤©APIå‘¼ã³å‡ºã—ã®æ’ä»–åˆ¶å¾¡ç”¨ãƒ­ãƒƒã‚¯
# åŒæ™‚ã«1ã¤ã®ã‚¸ãƒ§ãƒ–ã®ã¿APIã‚’å‘¼ã³å‡ºã›ã‚‹ã‚ˆã†ã«ã™ã‚‹
api_lock = threading.Lock()


def run_cache_warmup_job():
    """
    ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚¦ã‚©ãƒ¼ãƒ ã‚¢ãƒƒãƒ—ã‚¸ãƒ§ãƒ–

    æ¥½å¤©APIãƒ¬ãƒ¼ãƒˆåˆ¶é™ï¼ˆ1ãƒªã‚¯ã‚¨ã‚¹ãƒˆ/ç§’ï¼‰ã‚’éµå®ˆ
    - run_cache_warmupå†…ã§å„ãƒªã‚¯ã‚¨ã‚¹ãƒˆé–“ã«1ç§’ã®ã‚¦ã‚§ã‚¤ãƒˆã‚ã‚Š
    """
    # ãƒ­ãƒƒã‚¯ã‚’å–å¾—ï¼ˆä»–ã®ã‚¸ãƒ§ãƒ–ã¨ã®åŒæ™‚å®Ÿè¡Œã‚’é˜²æ­¢ï¼‰
    acquired = api_lock.acquire(blocking=False)
    if not acquired:
        logger.warning("â³ ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚¦ã‚©ãƒ¼ãƒ ã‚¢ãƒƒãƒ—: ä»–ã®ã‚¸ãƒ§ãƒ–ãŒå®Ÿè¡Œä¸­ã®ãŸã‚ã‚¹ã‚­ãƒƒãƒ—")
        return

    try:
        from app.scripts.run_cache_warmup import run_cache_warmup

        logger.info(f"ğŸ”¥ ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚¦ã‚©ãƒ¼ãƒ ã‚¢ãƒƒãƒ—é–‹å§‹: {datetime.now().isoformat()}")
        logger.info("   â€» æ¥½å¤©APIãƒ¬ãƒ¼ãƒˆåˆ¶é™: 1ãƒªã‚¯ã‚¨ã‚¹ãƒˆ/ç§’")

        result = run_cache_warmup()

        logger.info(
            f"âœ… ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚¦ã‚©ãƒ¼ãƒ ã‚¢ãƒƒãƒ—å®Œäº†: "
            f"æˆåŠŸ={result['success']}, ã‚¹ã‚­ãƒƒãƒ—={result['skipped']}, "
            f"ã‚¨ãƒ©ãƒ¼={result['errors']}, å‡¦ç†æ™‚é–“={result['duration_seconds']:.2f}ç§’"
        )
    except Exception as e:
        logger.error(f"âŒ ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚¦ã‚©ãƒ¼ãƒ ã‚¢ãƒƒãƒ—ã‚¨ãƒ©ãƒ¼: {str(e)}")
    finally:
        api_lock.release()


def run_price_update_job():
    """
    ä¾¡æ ¼æ›´æ–°ã‚¸ãƒ§ãƒ–

    æ¥½å¤©APIãƒ¬ãƒ¼ãƒˆåˆ¶é™ï¼ˆ1ãƒªã‚¯ã‚¨ã‚¹ãƒˆ/ç§’ï¼‰ã‚’éµå®ˆ
    - å„å•†å“ã®ä¾¡æ ¼å–å¾—é–“ã«1ç§’ã®ã‚¦ã‚§ã‚¤ãƒˆã‚’å…¥ã‚Œã‚‹
    """
    import time

    # ãƒ­ãƒƒã‚¯ã‚’å–å¾—ï¼ˆä»–ã®ã‚¸ãƒ§ãƒ–ã¨ã®åŒæ™‚å®Ÿè¡Œã‚’é˜²æ­¢ï¼‰
    acquired = api_lock.acquire(blocking=False)
    if not acquired:
        logger.warning("â³ ä¾¡æ ¼æ›´æ–°: ä»–ã®ã‚¸ãƒ§ãƒ–ãŒå®Ÿè¡Œä¸­ã®ãŸã‚ã‚¹ã‚­ãƒƒãƒ—")
        return

    try:
        from app.services.price_batch import PriceBatchProcessor
        from app.database import SessionLocal

        logger.info(f"ğŸ’° ä¾¡æ ¼æ›´æ–°ãƒãƒƒãƒé–‹å§‹: {datetime.now().isoformat()}")
        logger.info("   â€» æ¥½å¤©APIãƒ¬ãƒ¼ãƒˆåˆ¶é™: 1ãƒªã‚¯ã‚¨ã‚¹ãƒˆ/ç§’")

        db = SessionLocal()
        try:
            processor = PriceBatchProcessor(db)

            # ã‚¦ã‚©ãƒƒãƒãƒªã‚¹ãƒˆå•†å“ã‚’å–å¾—
            products = processor.get_watchlist_products()

            if not products:
                logger.info("âœ… ä¾¡æ ¼æ›´æ–°å®Œäº†: å‡¦ç†å¯¾è±¡ã®å•†å“ãªã—")
                return

            # å„å•†å“ã‚’å‡¦ç†ï¼ˆãƒ¬ãƒ¼ãƒˆåˆ¶é™ã‚’å®ˆã‚‹ï¼‰
            for i, product in enumerate(products):
                logger.info(f"  [{i+1}/{len(products)}] {product.name[:40]}...")
                processor.process_product(product)

                # æœ€å¾Œã®å•†å“ä»¥å¤–ã¯1ç§’å¾…æ©Ÿï¼ˆæ¥½å¤©APIãƒ¬ãƒ¼ãƒˆåˆ¶é™ï¼‰
                if i < len(products) - 1:
                    time.sleep(1.0)

            # ã‚³ãƒŸãƒƒãƒˆ
            db.commit()

            logger.info(
                f"âœ… ä¾¡æ ¼æ›´æ–°å®Œäº†: "
                f"å‡¦ç†={len(products)}, æ›´æ–°={processor.updated_count}, "
                f"ã‚¨ãƒ©ãƒ¼={processor.error_count}"
            )
        finally:
            db.close()

    except Exception as e:
        logger.error(f"âŒ ä¾¡æ ¼æ›´æ–°ãƒãƒƒãƒã‚¨ãƒ©ãƒ¼: {str(e)}")
    finally:
        api_lock.release()


def run_weekly_ranking_job():
    """
    é€±é–“TOP10ãƒ©ãƒ³ã‚­ãƒ³ã‚°ç”Ÿæˆã‚¸ãƒ§ãƒ–

    æ¯é€±æ—¥æ›œæ—¥ 0:00 ã«å®Ÿè¡Œ
    """
    # ãƒ­ãƒƒã‚¯ã‚’å–å¾—ï¼ˆä»–ã®ã‚¸ãƒ§ãƒ–ã¨ã®åŒæ™‚å®Ÿè¡Œã‚’é˜²æ­¢ï¼‰
    acquired = api_lock.acquire(blocking=False)
    if not acquired:
        logger.warning("â³ é€±é–“ãƒ©ãƒ³ã‚­ãƒ³ã‚°: ä»–ã®ã‚¸ãƒ§ãƒ–ãŒå®Ÿè¡Œä¸­ã®ãŸã‚ã‚¹ã‚­ãƒƒãƒ—")
        return

    try:
        from app.services.weekly_ranking_batch import run_weekly_ranking_batch

        logger.info(f"ğŸ“Š é€±é–“TOP10ãƒ©ãƒ³ã‚­ãƒ³ã‚°ç”Ÿæˆé–‹å§‹: {datetime.now().isoformat()}")

        result = run_weekly_ranking_batch()

        logger.info(
            f"âœ… é€±é–“ãƒ©ãƒ³ã‚­ãƒ³ã‚°ç”Ÿæˆå®Œäº†: "
            f"é€±={result.get('week_label', 'N/A')}, "
            f"æˆåŠŸ={result.get('success', 0)}, "
            f"ã‚¨ãƒ©ãƒ¼={result.get('errors', 0)}, "
            f"å‡¦ç†æ™‚é–“={result.get('duration_seconds', 0):.2f}ç§’"
        )
    except Exception as e:
        logger.error(f"âŒ é€±é–“ãƒ©ãƒ³ã‚­ãƒ³ã‚°ç”Ÿæˆã‚¨ãƒ©ãƒ¼: {str(e)}")
    finally:
        api_lock.release()


def start_scheduler():
    """ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ãƒ¼ã‚’é–‹å§‹"""
    if scheduler.running:
        logger.warning("ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ãƒ¼ã¯æ—¢ã«å®Ÿè¡Œä¸­ã§ã™")
        return

    # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚¦ã‚©ãƒ¼ãƒ ã‚¢ãƒƒãƒ—: 6æ™‚é–“ã”ã¨ï¼ˆ0:00, 6:00, 12:00, 18:00ï¼‰
    scheduler.add_job(
        run_cache_warmup_job,
        trigger=IntervalTrigger(hours=6),
        id="cache_warmup",
        name="ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚¦ã‚©ãƒ¼ãƒ ã‚¢ãƒƒãƒ—",
        replace_existing=True,
        max_instances=1,  # åŒæ™‚ã«1ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã®ã¿
    )

    # ä¾¡æ ¼æ›´æ–°: 6æ™‚é–“ã”ã¨ã€ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚¦ã‚©ãƒ¼ãƒ ã‚¢ãƒƒãƒ—ã‹ã‚‰3æ™‚é–“å¾Œ
    # ï¼ˆ3:00, 9:00, 15:00, 21:00ï¼‰
    # åŒæ™‚å®Ÿè¡Œã‚’é¿ã‘ã‚‹ãŸã‚ååˆ†ãªé–“éš”ã‚’ç¢ºä¿
    scheduler.add_job(
        run_price_update_job,
        trigger=IntervalTrigger(hours=6, start_date="2024-01-01 03:00:00"),
        id="price_update",
        name="ä¾¡æ ¼æ›´æ–°ãƒãƒƒãƒ",
        replace_existing=True,
        max_instances=1,  # åŒæ™‚ã«1ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã®ã¿
    )

    # é€±é–“TOP10ãƒ©ãƒ³ã‚­ãƒ³ã‚°ç”Ÿæˆ: æ¯é€±æ—¥æ›œæ—¥ 0:00
    scheduler.add_job(
        run_weekly_ranking_job,
        trigger=CronTrigger(day_of_week="sun", hour=0, minute=0),
        id="weekly_ranking",
        name="é€±é–“TOP10ãƒ©ãƒ³ã‚­ãƒ³ã‚°ç”Ÿæˆ",
        replace_existing=True,
        max_instances=1,
    )

    scheduler.start()
    logger.info("ğŸ“… ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ãƒ¼é–‹å§‹")
    logger.info("   - ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚¦ã‚©ãƒ¼ãƒ ã‚¢ãƒƒãƒ—: 6æ™‚é–“ã”ã¨")
    logger.info("   - ä¾¡æ ¼æ›´æ–°ãƒãƒƒãƒ: 6æ™‚é–“ã”ã¨ï¼ˆ3æ™‚é–“ã‚ªãƒ•ã‚»ãƒƒãƒˆï¼‰")
    logger.info("   - é€±é–“TOP10ãƒ©ãƒ³ã‚­ãƒ³ã‚°: æ¯é€±æ—¥æ›œæ—¥ 0:00")
    logger.info("   â€» æ¥½å¤©APIãƒ¬ãƒ¼ãƒˆåˆ¶é™ï¼ˆ1req/secï¼‰ã‚’éµå®ˆ")
    logger.info("   â€» ã‚¸ãƒ§ãƒ–ã¯æ’ä»–åˆ¶å¾¡ã«ã‚ˆã‚ŠåŒæ™‚å®Ÿè¡Œã•ã‚Œã¾ã›ã‚“")


def stop_scheduler():
    """ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ãƒ¼ã‚’åœæ­¢"""
    if scheduler.running:
        scheduler.shutdown(wait=False)
        logger.info("ğŸ“… ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ãƒ¼åœæ­¢")


def get_scheduler_status() -> dict:
    """ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ãƒ¼ã®çŠ¶æ…‹ã‚’å–å¾—"""
    jobs = []
    if scheduler.running:
        for job in scheduler.get_jobs():
            jobs.append({
                "id": job.id,
                "name": job.name,
                "next_run": job.next_run_time.isoformat() if job.next_run_time else None,
            })

    return {
        "running": scheduler.running,
        "jobs": jobs,
        "note": "æ¥½å¤©APIãƒ¬ãƒ¼ãƒˆåˆ¶é™: 1ãƒªã‚¯ã‚¨ã‚¹ãƒˆ/ç§’",
    }
